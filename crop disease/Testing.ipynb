{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step\n",
      "AppleCedarRust1.JPG predicted as Apple___Cedar_apple_rust\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
      "AppleCedarRust2.JPG predicted as Apple___Cedar_apple_rust\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
      "AppleCedarRust3.JPG predicted as Apple___Cedar_apple_rust\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step\n",
      "AppleCedarRust4.JPG predicted as Apple___Cedar_apple_rust\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "AppleScab1.JPG predicted as Apple___Apple_scab\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "AppleScab2.JPG predicted as Apple___Apple_scab\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "AppleScab3.JPG predicted as Squash___Powdery_mildew\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "CornCommonRust1.JPG predicted as Corn_(maize)___Common_rust_\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n",
      "CornCommonRust2.JPG predicted as Corn_(maize)___Common_rust_\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "CornCommonRust3.JPG predicted as Corn_(maize)___Common_rust_\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "PotatoEarlyBlight1.JPG predicted as Potato___Early_blight\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "PotatoEarlyBlight2.JPG predicted as Potato___Early_blight\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
      "PotatoEarlyBlight3.JPG predicted as Potato___Early_blight\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
      "PotatoEarlyBlight4.JPG predicted as Potato___Early_blight\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "PotatoEarlyBlight5.JPG predicted as Potato___Early_blight\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "PotatoHealthy1.JPG predicted as Potato___healthy\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "PotatoHealthy2.JPG predicted as Potato___healthy\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "TomatoEarlyBlight1.JPG predicted as Tomato___Early_blight\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "TomatoEarlyBlight2.JPG predicted as Tomato___Late_blight\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "TomatoEarlyBlight3.JPG predicted as Tomato___Early_blight\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "TomatoEarlyBlight4.JPG predicted as Tomato___Early_blight\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "TomatoEarlyBlight5.JPG predicted as Tomato___Early_blight\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
      "TomatoEarlyBlight6.JPG predicted as Tomato___Early_blight\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
      "TomatoHealthy1.JPG predicted as Tomato___healthy\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "TomatoHealthy2.JPG predicted as Tomato___healthy\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "TomatoHealthy3.JPG predicted as Tomato___healthy\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "TomatoHealthy4.JPG predicted as Tomato___healthy\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
      "TomatoYellowCurlVirus1.JPG predicted as Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "TomatoYellowCurlVirus2.JPG predicted as Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
      "TomatoYellowCurlVirus3.JPG predicted as Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "TomatoYellowCurlVirus4.JPG predicted as Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
      "TomatoYellowCurlVirus5.JPG predicted as Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "TomatoYellowCurlVirus6.JPG predicted as Tomato___Tomato_Yellow_Leaf_Curl_Virus\n"
     ]
    }
   ],
   "source": [
    "# VGG16 Testing\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "\n",
    "testdir = r\"C:\\Users\\HP-OMEN\\OneDrive\\Desktop\\crop disease\\test\"\n",
    "weightsfilepath = r\"C:\\Users\\HP-OMEN\\OneDrive\\Desktop\\crop disease\\model ouput\\bestweights.hdf5\"\n",
    "\n",
    "\n",
    "class_labels = [\n",
    "    'Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy',\n",
    "    'Blueberry___healthy', 'Cherry_(including_sour)___Powdery_mildew', 'Cherry_(including_sour)___healthy',\n",
    "    'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot', 'Corn_(maize)___Common_rust_',\n",
    "    'Corn_(maize)___Northern_Leaf_Blight', 'Corn_(maize)___healthy', 'Grape___Black_rot',\n",
    "    'Grape___Esca_(Black_Measles)', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Grape___healthy',\n",
    "    'Orange___Haunglongbing_(Citrus_greening)', 'Peach___Bacterial_spot', 'Peach___healthy',\n",
    "    'Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy', 'Potato___Early_blight',\n",
    "    'Potato___Late_blight', 'Potato___healthy', 'Raspberry___healthy', 'Soybean___healthy',\n",
    "    'Squash___Powdery_mildew', 'Strawberry___Leaf_scorch', 'Strawberry___healthy',\n",
    "    'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___Late_blight', 'Tomato___Leaf_Mold',\n",
    "    'Tomato___Septoria_leaf_spot', 'Tomato___Spider_mites Two-spotted_spider_mite', \n",
    "    'Tomato___Target_Spot', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', \n",
    "    'Tomato___Tomato_mosaic_virus', 'Tomato___healthy'\n",
    "]\n",
    "\n",
    "\n",
    "def define_model(in_shape=(224, 224, 3), out_shape=len(class_labels)):\n",
    "    base_model = VGG16(include_top=False, input_shape=in_shape, weights=None)\n",
    "    for layer in base_model.layers[:-4]:  # Freeze all except last 4 layers\n",
    "        layer.trainable = False\n",
    "    x = Flatten()(base_model.output)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    output = Dense(out_shape, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.inputs, outputs=output)\n",
    "    model.load_weights(weightsfilepath)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_image(filename):\n",
    "    img = load_img(filename, target_size=(224, 224))\n",
    "    img = img_to_array(img) / 255.0\n",
    "    return np.expand_dims(img, axis=0)\n",
    "\n",
    "\n",
    "model = define_model()\n",
    "\n",
    "\n",
    "for filename in os.listdir(testdir):\n",
    "    filepath = os.path.join(testdir, filename)\n",
    "    img = load_image(filepath)\n",
    "    prediction = model.predict(img)\n",
    "    predicted_class_name = class_labels[np.argmax(prediction)]\n",
    "    print(f\"{filename} predicted as {predicted_class_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EfficientNet testing\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "# Define the path to the test directory and the model file\n",
    "test_dir = r\"C:\\Users\\HP-OMEN\\OneDrive\\Desktop\\crop disease\\test\"  # Update with your test directory\n",
    "model_path = r\"C:\\Users\\HP-OMEN\\OneDrive\\Desktop\\crop disease\\models_trained\\efficientnet_model.h5\"  # Update with your model path\n",
    "\n",
    "# Load the EfficientNet model\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Class labels (update as needed for your specific dataset)\n",
    "class_labels = [\n",
    "    'Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy',\n",
    "    'Blueberry___healthy', 'Cherry_(including_sour)___Powdery_mildew', 'Cherry_(including_sour)___healthy',\n",
    "    'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot', 'Corn_(maize)___Common_rust_',\n",
    "    'Corn_(maize)___Northern_Leaf_Blight', 'Corn_(maize)___healthy', 'Grape___Black_rot',\n",
    "    'Grape___Esca_(Black_Measles)', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Grape___healthy',\n",
    "    'Orange___Haunglongbing_(Citrus_greening)', 'Peach___Bacterial_spot', 'Peach___healthy',\n",
    "    'Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy', 'Potato___Early_blight',\n",
    "    'Potato___Late_blight', 'Potato___healthy', 'Raspberry___healthy', 'Soybean___healthy',\n",
    "    'Squash___Powdery_mildew', 'Strawberry___Leaf_scorch', 'Strawberry___healthy',\n",
    "    'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___Late_blight', 'Tomato___Leaf_Mold',\n",
    "    'Tomato___Septoria_leaf_spot', 'Tomato___Spider_mites Two-spotted_spider_mite', \n",
    "    'Tomato___Target_Spot', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', \n",
    "    'Tomato___Tomato_mosaic_virus', 'Tomato___healthy'\n",
    "]\n",
    "\n",
    "# Function to load and preprocess an image\n",
    "def load_and_preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(224, 224))  # Resize image to 224x224\n",
    "    img_array = img_to_array(img)  # Convert image to array\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array = preprocess_input(img_array)  # Preprocess the image for EfficientNet\n",
    "    return img_array\n",
    "\n",
    "# Iterate through test images and make predictions\n",
    "for filename in os.listdir(test_dir):\n",
    "    image_path = os.path.join(test_dir, filename)\n",
    "    img_array = load_and_preprocess_image(image_path)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
    "    predicted_class = class_labels[predicted_class_index]\n",
    "\n",
    "    print(f\"Image: {filename} -> Predicted Class: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP-OMEN\\AppData\\Local\\Temp\\ipykernel_22252\\1037546358.py:42: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(weights_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: AppleCedarRust1.JPG -> Predicted Class: Apple___Cedar_apple_rust\n",
      "Image: AppleCedarRust2.JPG -> Predicted Class: Apple___Cedar_apple_rust\n",
      "Image: AppleCedarRust3.JPG -> Predicted Class: Pepper,_bell___Bacterial_spot\n",
      "Image: AppleCedarRust4.JPG -> Predicted Class: Apple___Cedar_apple_rust\n",
      "Image: AppleScab1.JPG -> Predicted Class: Apple___Apple_scab\n",
      "Image: AppleScab2.JPG -> Predicted Class: Apple___Apple_scab\n",
      "Image: AppleScab3.JPG -> Predicted Class: Apple___Apple_scab\n",
      "Image: CornCommonRust1.JPG -> Predicted Class: Corn_(maize)___Common_rust_\n",
      "Image: CornCommonRust2.JPG -> Predicted Class: Corn_(maize)___Common_rust_\n",
      "Image: CornCommonRust3.JPG -> Predicted Class: Corn_(maize)___Common_rust_\n",
      "Image: PotatoEarlyBlight1.JPG -> Predicted Class: Potato___Early_blight\n",
      "Image: PotatoEarlyBlight2.JPG -> Predicted Class: Potato___Early_blight\n",
      "Image: PotatoEarlyBlight3.JPG -> Predicted Class: Potato___Early_blight\n",
      "Image: PotatoEarlyBlight4.JPG -> Predicted Class: Potato___Early_blight\n",
      "Image: PotatoEarlyBlight5.JPG -> Predicted Class: Potato___Early_blight\n",
      "Image: PotatoHealthy1.JPG -> Predicted Class: Potato___healthy\n",
      "Image: PotatoHealthy2.JPG -> Predicted Class: Potato___healthy\n",
      "Image: TomatoEarlyBlight1.JPG -> Predicted Class: Tomato___Early_blight\n",
      "Image: TomatoEarlyBlight2.JPG -> Predicted Class: Tomato___Early_blight\n",
      "Image: TomatoEarlyBlight3.JPG -> Predicted Class: Tomato___Early_blight\n",
      "Image: TomatoEarlyBlight4.JPG -> Predicted Class: Tomato___Bacterial_spot\n",
      "Image: TomatoEarlyBlight5.JPG -> Predicted Class: Tomato___Early_blight\n",
      "Image: TomatoEarlyBlight6.JPG -> Predicted Class: Tomato___Early_blight\n",
      "Image: TomatoHealthy1.JPG -> Predicted Class: Tomato___healthy\n",
      "Image: TomatoHealthy2.JPG -> Predicted Class: Tomato___healthy\n",
      "Image: TomatoHealthy3.JPG -> Predicted Class: Tomato___healthy\n",
      "Image: TomatoHealthy4.JPG -> Predicted Class: Tomato___healthy\n",
      "Image: TomatoYellowCurlVirus1.JPG -> Predicted Class: Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "Image: TomatoYellowCurlVirus2.JPG -> Predicted Class: Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "Image: TomatoYellowCurlVirus3.JPG -> Predicted Class: Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "Image: TomatoYellowCurlVirus4.JPG -> Predicted Class: Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "Image: TomatoYellowCurlVirus5.JPG -> Predicted Class: Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "Image: TomatoYellowCurlVirus6.JPG -> Predicted Class: Tomato___Tomato_Yellow_Leaf_Curl_Virus\n"
     ]
    }
   ],
   "source": [
    "# MobileV2 Testing\n",
    "import os\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the path to the test directory and the model weights\n",
    "test_dir = r\"C:\\Users\\HP-OMEN\\OneDrive\\Desktop\\crop disease\\test\"\n",
    "weights_path = r\"models_trained\\mobilenetv2_plantdisease_E=8_A=97.pth\"\n",
    "\n",
    "# Class labels\n",
    "class_labels = [\n",
    "    'Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy',\n",
    "    'Blueberry___healthy', 'Cherry_(including_sour)___Powdery_mildew', 'Cherry_(including_sour)___healthy',\n",
    "    'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot', 'Corn_(maize)___Common_rust_',\n",
    "    'Corn_(maize)___Northern_Leaf_Blight', 'Corn_(maize)___healthy', 'Grape___Black_rot',\n",
    "    'Grape___Esca_(Black_Measles)', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Grape___healthy',\n",
    "    'Orange___Haunglongbing_(Citrus_greening)', 'Peach___Bacterial_spot', 'Peach___healthy',\n",
    "    'Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy', 'Potato___Early_blight',\n",
    "    'Potato___Late_blight', 'Potato___healthy', 'Raspberry___healthy', 'Soybean___healthy',\n",
    "    'Squash___Powdery_mildew', 'Strawberry___Leaf_scorch', 'Strawberry___healthy',\n",
    "    'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___Late_blight', 'Tomato___Leaf_Mold',\n",
    "    'Tomato___Septoria_leaf_spot', 'Tomato___Spider_mites Two-spotted_spider_mite', \n",
    "    'Tomato___Target_Spot', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', \n",
    "    'Tomato___Tomato_mosaic_virus', 'Tomato___healthy'\n",
    "]\n",
    "\n",
    "# Load the MobileNetV2 model and modify the classifier for 38 classes\n",
    "model = models.mobilenet_v2(pretrained=False)\n",
    "model.classifier[1] = nn.Sequential(\n",
    "    nn.Linear(model.classifier[1].in_features, 4096),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.25),\n",
    "    nn.BatchNorm1d(4096),\n",
    "    nn.Linear(4096, len(class_labels)),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "model.load_state_dict(torch.load(weights_path))\n",
    "model = model.to(device)\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "# Define image transformation for testing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Function to load and preprocess an image\n",
    "def load_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image)\n",
    "    return image.unsqueeze(0).to(device)\n",
    "\n",
    "# Iterate through test images and make predictions\n",
    "for filename in os.listdir(test_dir):\n",
    "    image_path = os.path.join(test_dir, filename)\n",
    "    image = load_image(image_path)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predicted_class = class_labels[predicted.item()]\n",
    "\n",
    "    print(f\"Image: {filename} -> Predicted Class: {predicted_class}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
